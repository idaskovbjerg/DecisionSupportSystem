{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Lag1   Lag2   Lag3   Lag4   Lag5   Volume  Today Direction\n",
      "Year                                                                   \n",
      "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.19130  0.959        Up\n",
      "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.29650  1.032        Up\n",
      "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.41120 -0.623      Down\n",
      "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.27600  0.614        Up\n",
      "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.20570  0.213        Up\n",
      "2001-01-01  0.213  0.614 -0.623  1.032  0.959  1.34910  1.392        Up\n",
      "2001-01-01  1.392  0.213  0.614 -0.623  1.032  1.44500 -0.403      Down\n",
      "2001-01-01 -0.403  1.392  0.213  0.614 -0.623  1.40780  0.027        Up\n",
      "2001-01-01  0.027 -0.403  1.392  0.213  0.614  1.16400  1.303        Up\n",
      "2001-01-01  1.303  0.027 -0.403  1.392  0.213  1.23260  0.287        Up\n",
      "2001-01-01  0.287  1.303  0.027 -0.403  1.392  1.30900 -0.498      Down\n",
      "2001-01-01 -0.498  0.287  1.303  0.027 -0.403  1.25800 -0.189      Down\n",
      "2001-01-01 -0.189 -0.498  0.287  1.303  0.027  1.09800  0.680        Up\n",
      "2001-01-01  0.680 -0.189 -0.498  0.287  1.303  1.05310  0.701        Up\n",
      "2001-01-01  0.701  0.680 -0.189 -0.498  0.287  1.14980 -0.562      Down\n",
      "2001-01-01 -0.562  0.701  0.680 -0.189 -0.498  1.29530  0.546        Up\n",
      "2001-01-01  0.546 -0.562  0.701  0.680 -0.189  1.11880 -1.747      Down\n",
      "2001-01-01 -1.747  0.546 -0.562  0.701  0.680  1.04840  0.359        Up\n",
      "2001-01-01  0.359 -1.747  0.546 -0.562  0.701  1.01300 -0.151      Down\n",
      "2001-01-01 -0.151  0.359 -1.747  0.546 -0.562  1.05960 -0.841      Down\n",
      "2001-01-01 -0.841 -0.151  0.359 -1.747  0.546  1.15830 -0.623      Down\n",
      "2001-01-01 -0.623 -0.841 -0.151  0.359 -1.747  1.10720 -1.334      Down\n",
      "2001-01-01 -1.334 -0.623 -0.841 -0.151  0.359  1.07550  1.183        Up\n",
      "2001-01-01  1.183 -1.334 -0.623 -0.841 -0.151  1.03910 -0.865      Down\n",
      "2001-01-01 -0.865  1.183 -1.334 -0.623 -0.841  1.07520 -0.218      Down\n",
      "2001-01-01 -0.218 -0.865  1.183 -1.334 -0.623  1.15030  0.812        Up\n",
      "2001-01-01  0.812 -0.218 -0.865  1.183 -1.334  1.15370 -1.891      Down\n",
      "2001-01-01 -1.891  0.812 -0.218 -0.865  1.183  1.25720 -1.736      Down\n",
      "2001-01-01 -1.736 -1.891  0.812 -0.218 -0.865  1.11220 -1.851      Down\n",
      "2001-01-01 -1.851 -1.736 -1.891  0.812 -0.218  1.20850 -0.195      Down\n",
      "...           ...    ...    ...    ...    ...      ...    ...       ...\n",
      "2005-01-01  0.179 -0.385 -0.078  0.305  0.845  2.12158  0.941        Up\n",
      "2005-01-01  0.941  0.179 -0.385 -0.078  0.305  2.29804  0.440        Up\n",
      "2005-01-01  0.440  0.941  0.179 -0.385 -0.078  2.45329  0.527        Up\n",
      "2005-01-01  0.527  0.440  0.941  0.179 -0.385  2.11735  0.508        Up\n",
      "2005-01-01  0.508  0.527  0.440  0.941  0.179  2.29142  0.347        Up\n",
      "2005-01-01  0.347  0.508  0.527  0.440  0.941  1.98540  0.209        Up\n",
      "2005-01-01  0.209  0.347  0.508  0.527  0.440  0.72494 -0.851      Down\n",
      "2005-01-01 -0.851  0.209  0.347  0.508  0.527  2.01690  0.002        Up\n",
      "2005-01-01  0.002 -0.851  0.209  0.347  0.508  2.26834 -0.636      Down\n",
      "2005-01-01 -0.636  0.002 -0.851  0.209  0.347  2.37469  1.216        Up\n",
      "2005-01-01  1.216 -0.636  0.002 -0.851  0.209  2.61483  0.032        Up\n",
      "2005-01-01  0.032  1.216 -0.636  0.002 -0.851  2.12558 -0.236      Down\n",
      "2005-01-01 -0.236  0.032  1.216 -0.636  0.002  2.32584  0.128        Up\n",
      "2005-01-01  0.128 -0.236  0.032  1.216 -0.636  2.11074 -0.501      Down\n",
      "2005-01-01 -0.501  0.128 -0.236  0.032  1.216  2.09383 -0.122      Down\n",
      "2005-01-01 -0.122 -0.501  0.128 -0.236  0.032  2.17830  0.281        Up\n",
      "2005-01-01  0.281 -0.122 -0.501  0.128 -0.236  1.89629  0.084        Up\n",
      "2005-01-01  0.084  0.281 -0.122 -0.501  0.128  1.87655  0.555        Up\n",
      "2005-01-01  0.555  0.084  0.281 -0.122 -0.501  2.39002  0.419        Up\n",
      "2005-01-01  0.419  0.555  0.084  0.281 -0.122  2.14552 -0.141      Down\n",
      "2005-01-01 -0.141  0.419  0.555  0.084  0.281  2.18059 -0.285      Down\n",
      "2005-01-01 -0.285 -0.141  0.419  0.555  0.084  2.58419 -0.584      Down\n",
      "2005-01-01 -0.584 -0.285 -0.141  0.419  0.555  2.20881 -0.024      Down\n",
      "2005-01-01 -0.024 -0.584 -0.285 -0.141  0.419  1.99669  0.252        Up\n",
      "2005-01-01  0.252 -0.024 -0.584 -0.285 -0.141  2.06517  0.422        Up\n",
      "2005-01-01  0.422  0.252 -0.024 -0.584 -0.285  1.88850  0.043        Up\n",
      "2005-01-01  0.043  0.422  0.252 -0.024 -0.584  1.28581 -0.955      Down\n",
      "2005-01-01 -0.955  0.043  0.422  0.252 -0.024  1.54047  0.130        Up\n",
      "2005-01-01  0.130 -0.955  0.043  0.422  0.252  1.42236 -0.298      Down\n",
      "2005-01-01 -0.298  0.130 -0.955  0.043  0.422  1.38254 -0.489      Down\n",
      "\n",
      "[1250 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# https://realpython.com/python-csv/\n",
    "# REad CSV file python\n",
    "import pandas\n",
    "df = pandas.read_csv('Dataset/Smarket.csv',usecols=range(1,10), index_col=0, parse_dates=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][['Lag1','Lag2']]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "X_test = df['2005':][['Lag1','Lag2']]\n",
    "y_test = df['2005':]['Direction']\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "pred = lda.fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49198397, 0.50801603])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pi_hat1 og pi_hat2\n",
    "lda.priors_\n",
    "# in other words, 49.2% of the training observations correspond to days during which the market went down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04279022,  0.03389409],\n",
       "       [-0.03954635, -0.03132544]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05544078, -0.0443452 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These do not seem to correspond to the values from the R output in the book?\n",
    "lda.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35,  35],\n",
       "       [ 76, 106]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA prediction \n",
    "confusion_matrix(y_test, pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.500     0.315     0.387       111\n",
      "          Up      0.582     0.752     0.656       141\n",
      "\n",
      "   micro avg      0.560     0.560     0.560       252\n",
      "   macro avg      0.541     0.534     0.522       252\n",
      "weighted avg      0.546     0.560     0.538       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([ 70, 182], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50% threshold: allows us to recreate the predictions\n",
    "pred_p = lda.predict_proba(X_test)\n",
    "\n",
    "np.unique(pred_p[:,1]>0.5, return_counts=True)\n",
    "\n",
    "#Notice that the posterior probability output by the model corresponds to the probability that the market will decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False]), array([252], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% threshold\n",
    "np.unique(pred_p[:,1]>0.9, return_counts=True)\n",
    "\n",
    "# No days in 2005 meet that threshold! In fact, the greatest posterior probability of decrease in all of 2005 was 52.02%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
