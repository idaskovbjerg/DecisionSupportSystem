{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing, neighbors, linear_model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year   Lag1   Lag2   Lag3   Lag4   Lag5   Volume  Today Direction\n",
      "1     2001  0.381 -0.192 -2.624 -1.055  5.010  1.19130  0.959        Up\n",
      "2     2001  0.959  0.381 -0.192 -2.624 -1.055  1.29650  1.032        Up\n",
      "3     2001  1.032  0.959  0.381 -0.192 -2.624  1.41120 -0.623      Down\n",
      "4     2001 -0.623  1.032  0.959  0.381 -0.192  1.27600  0.614        Up\n",
      "5     2001  0.614 -0.623  1.032  0.959  0.381  1.20570  0.213        Up\n",
      "6     2001  0.213  0.614 -0.623  1.032  0.959  1.34910  1.392        Up\n",
      "7     2001  1.392  0.213  0.614 -0.623  1.032  1.44500 -0.403      Down\n",
      "8     2001 -0.403  1.392  0.213  0.614 -0.623  1.40780  0.027        Up\n",
      "9     2001  0.027 -0.403  1.392  0.213  0.614  1.16400  1.303        Up\n",
      "10    2001  1.303  0.027 -0.403  1.392  0.213  1.23260  0.287        Up\n",
      "11    2001  0.287  1.303  0.027 -0.403  1.392  1.30900 -0.498      Down\n",
      "12    2001 -0.498  0.287  1.303  0.027 -0.403  1.25800 -0.189      Down\n",
      "13    2001 -0.189 -0.498  0.287  1.303  0.027  1.09800  0.680        Up\n",
      "14    2001  0.680 -0.189 -0.498  0.287  1.303  1.05310  0.701        Up\n",
      "15    2001  0.701  0.680 -0.189 -0.498  0.287  1.14980 -0.562      Down\n",
      "16    2001 -0.562  0.701  0.680 -0.189 -0.498  1.29530  0.546        Up\n",
      "17    2001  0.546 -0.562  0.701  0.680 -0.189  1.11880 -1.747      Down\n",
      "18    2001 -1.747  0.546 -0.562  0.701  0.680  1.04840  0.359        Up\n",
      "19    2001  0.359 -1.747  0.546 -0.562  0.701  1.01300 -0.151      Down\n",
      "20    2001 -0.151  0.359 -1.747  0.546 -0.562  1.05960 -0.841      Down\n",
      "21    2001 -0.841 -0.151  0.359 -1.747  0.546  1.15830 -0.623      Down\n",
      "22    2001 -0.623 -0.841 -0.151  0.359 -1.747  1.10720 -1.334      Down\n",
      "23    2001 -1.334 -0.623 -0.841 -0.151  0.359  1.07550  1.183        Up\n",
      "24    2001  1.183 -1.334 -0.623 -0.841 -0.151  1.03910 -0.865      Down\n",
      "25    2001 -0.865  1.183 -1.334 -0.623 -0.841  1.07520 -0.218      Down\n",
      "26    2001 -0.218 -0.865  1.183 -1.334 -0.623  1.15030  0.812        Up\n",
      "27    2001  0.812 -0.218 -0.865  1.183 -1.334  1.15370 -1.891      Down\n",
      "28    2001 -1.891  0.812 -0.218 -0.865  1.183  1.25720 -1.736      Down\n",
      "29    2001 -1.736 -1.891  0.812 -0.218 -0.865  1.11220 -1.851      Down\n",
      "30    2001 -1.851 -1.736 -1.891  0.812 -0.218  1.20850 -0.195      Down\n",
      "...    ...    ...    ...    ...    ...    ...      ...    ...       ...\n",
      "1221  2005  0.179 -0.385 -0.078  0.305  0.845  2.12158  0.941        Up\n",
      "1222  2005  0.941  0.179 -0.385 -0.078  0.305  2.29804  0.440        Up\n",
      "1223  2005  0.440  0.941  0.179 -0.385 -0.078  2.45329  0.527        Up\n",
      "1224  2005  0.527  0.440  0.941  0.179 -0.385  2.11735  0.508        Up\n",
      "1225  2005  0.508  0.527  0.440  0.941  0.179  2.29142  0.347        Up\n",
      "1226  2005  0.347  0.508  0.527  0.440  0.941  1.98540  0.209        Up\n",
      "1227  2005  0.209  0.347  0.508  0.527  0.440  0.72494 -0.851      Down\n",
      "1228  2005 -0.851  0.209  0.347  0.508  0.527  2.01690  0.002        Up\n",
      "1229  2005  0.002 -0.851  0.209  0.347  0.508  2.26834 -0.636      Down\n",
      "1230  2005 -0.636  0.002 -0.851  0.209  0.347  2.37469  1.216        Up\n",
      "1231  2005  1.216 -0.636  0.002 -0.851  0.209  2.61483  0.032        Up\n",
      "1232  2005  0.032  1.216 -0.636  0.002 -0.851  2.12558 -0.236      Down\n",
      "1233  2005 -0.236  0.032  1.216 -0.636  0.002  2.32584  0.128        Up\n",
      "1234  2005  0.128 -0.236  0.032  1.216 -0.636  2.11074 -0.501      Down\n",
      "1235  2005 -0.501  0.128 -0.236  0.032  1.216  2.09383 -0.122      Down\n",
      "1236  2005 -0.122 -0.501  0.128 -0.236  0.032  2.17830  0.281        Up\n",
      "1237  2005  0.281 -0.122 -0.501  0.128 -0.236  1.89629  0.084        Up\n",
      "1238  2005  0.084  0.281 -0.122 -0.501  0.128  1.87655  0.555        Up\n",
      "1239  2005  0.555  0.084  0.281 -0.122 -0.501  2.39002  0.419        Up\n",
      "1240  2005  0.419  0.555  0.084  0.281 -0.122  2.14552 -0.141      Down\n",
      "1241  2005 -0.141  0.419  0.555  0.084  0.281  2.18059 -0.285      Down\n",
      "1242  2005 -0.285 -0.141  0.419  0.555  0.084  2.58419 -0.584      Down\n",
      "1243  2005 -0.584 -0.285 -0.141  0.419  0.555  2.20881 -0.024      Down\n",
      "1244  2005 -0.024 -0.584 -0.285 -0.141  0.419  1.99669  0.252        Up\n",
      "1245  2005  0.252 -0.024 -0.584 -0.285 -0.141  2.06517  0.422        Up\n",
      "1246  2005  0.422  0.252 -0.024 -0.584 -0.285  1.88850  0.043        Up\n",
      "1247  2005  0.043  0.422  0.252 -0.024 -0.584  1.28581 -0.955      Down\n",
      "1248  2005 -0.955  0.043  0.422  0.252 -0.024  1.54047  0.130        Up\n",
      "1249  2005  0.130 -0.955  0.043  0.422  0.252  1.42236 -0.298      Down\n",
      "1250  2005 -0.298  0.130 -0.955  0.043  0.422  1.38254 -0.489      Down\n",
      "\n",
      "[1250 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# https://realpython.com/python-csv/\n",
    "# REad CSV file python\n",
    "import pandas\n",
    "df = pandas.read_csv('Dataset/Smarket.csv', usecols=range(0,10), index_col=0, parse_dates=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.formula.glm('Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume', family=sm.families.Binomial(), data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1243\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
      "Date:                                  Fri, 26 Apr 2019   Deviance:                       1727.6\n",
      "Time:                                          11:05:16   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49291587, 0.51853212, 0.51886117, ..., 0.4607317 , 0.47388171,\n",
       "       0.48208344])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data set is splitted into two - before 2004 and after 2004\n",
      "Before is used as training set and after is test.\n",
      "\n",
      "Score of test data\n",
      "0.5595238095238095\n",
      "\n",
      " Predicted  Down   Up  All\n",
      "True                     \n",
      "Down         35   76  111\n",
      "Up           35  106  141\n",
      "All          70  182  252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ida_s\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Splitting in train and test set\n",
    "df_train = df[df.Year < 2005]\n",
    "df_test = df[df.Year == 2005]\n",
    "df_X_train = df_train[:][['Lag1', 'Lag2']]\n",
    "df_X_test = df_test[:][['Lag1', 'Lag2']]\n",
    "df_y_train = df_train[:]['Direction']\n",
    "df_y_test = df_test[:]['Direction']\n",
    "\n",
    "# Fitting the model based on train set\n",
    "lr = linear_model.LogisticRegression()\n",
    "ex = lr.fit(df_X_train, df_y_train)\n",
    "print('\\nData set is splitted into two - before 2004 and after 2004\\nBefore is used as training set and after is test.')\n",
    "print('\\nScore of test data')\n",
    "#y_pred = lr.predict(smarket_X_test)\n",
    "print(lr.score(df_X_test, df_y_test))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\n',pd.crosstab(df_y_test, lr.predict(df_X_test), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# # Classification report\n",
    "# print(metrics.classification_report(smarket_y_train, lr.predict(smarket_X_test)))\n",
    "\n",
    "#smarket.loc[smarket['Direction']=='Down', 'Direction']=0\n",
    "#smarket.loc[smarket['Direction']=='Up', 'Direction']=1\n",
    "# X = smarket['Year']#.values.reshape(-1,1)\n",
    "# Y = smarket['Direction'].values.reshape(-1,1)\n",
    "\n",
    "# LogR = LogisticRegression()\n",
    "# LogR.fit(X,np.ravel(Y.astype(int)))\n",
    "\n",
    "#matplotlib scatter funcion w/ logistic regression\n",
    "# plt.scatter(X, Y)\n",
    "# plt.xlabel('s')\n",
    "# plt.ylabel('ss')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
