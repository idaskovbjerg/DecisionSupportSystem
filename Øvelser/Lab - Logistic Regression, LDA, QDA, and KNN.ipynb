{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Logistic Regression, LDA, QDA, and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.1 The Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import neighbors, linear_model, preprocessing\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "1  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "3  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "4  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "5  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file python\n",
    "df = pd.read_csv('Dataset/Smarket.csv',usecols=range(0,10), index_col=0, parse_dates=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.030095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.026155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.010250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.033195</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.035689</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.029788</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>-0.034860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.030095</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.034860</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year      Lag1      Lag2      Lag3      Lag4      Lag5    Volume  \\\n",
       "Year    1.000000  0.029700  0.030596  0.033195  0.035689  0.029788  0.539006   \n",
       "Lag1    0.029700  1.000000 -0.026294 -0.010803 -0.002986 -0.005675  0.040910   \n",
       "Lag2    0.030596 -0.026294  1.000000 -0.025897 -0.010854 -0.003558 -0.043383   \n",
       "Lag3    0.033195 -0.010803 -0.025897  1.000000 -0.024051 -0.018808 -0.041824   \n",
       "Lag4    0.035689 -0.002986 -0.010854 -0.024051  1.000000 -0.027084 -0.048414   \n",
       "Lag5    0.029788 -0.005675 -0.003558 -0.018808 -0.027084  1.000000 -0.022002   \n",
       "Volume  0.539006  0.040910 -0.043383 -0.041824 -0.048414 -0.022002  1.000000   \n",
       "Today   0.030095 -0.026155 -0.010250 -0.002448 -0.006900 -0.034860  0.014592   \n",
       "\n",
       "           Today  \n",
       "Year    0.030095  \n",
       "Lag1   -0.026155  \n",
       "Lag2   -0.010250  \n",
       "Lag3   -0.002448  \n",
       "Lag4   -0.006900  \n",
       "Lag5   -0.034860  \n",
       "Volume  0.014592  \n",
       "Today   1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ida_s\\Anaconda3\\lib\\site-packages\\seaborn\\regression.py:546: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1c3c1c99400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(\"Year\", \"Volume\", data=df, size=4.5, height=10, aspect=2)\n",
    "\n",
    "#sns.boxplot(\"Year\",\"Volume\",data=df)\n",
    "# https://towardsdatascience.com/a-guide-to-pandas-and-matplotlib-for-data-exploration-56fad95f951c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the Smarket data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.formula.glm('Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume', family=sm.families.Binomial(), data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Generalized Linear Model Regression Results                           \n",
      "================================================================================================\n",
      "Dep. Variable:     ['Direction[Down]', 'Direction[Up]']   No. Observations:                 1250\n",
      "Model:                                              GLM   Df Residuals:                     1243\n",
      "Model Family:                                  Binomial   Df Model:                            6\n",
      "Link Function:                                    logit   Scale:                          1.0000\n",
      "Method:                                            IRLS   Log-Likelihood:                -863.79\n",
      "Date:                                  Sat, 27 Apr 2019   Deviance:                       1727.6\n",
      "Time:                                          22:45:51   Pearson chi2:                 1.25e+03\n",
      "No. Iterations:                                       4   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1260      0.241      0.523      0.601      -0.346       0.598\n",
      "Lag1           0.0731      0.050      1.457      0.145      -0.025       0.171\n",
      "Lag2           0.0423      0.050      0.845      0.398      -0.056       0.140\n",
      "Lag3          -0.0111      0.050     -0.222      0.824      -0.109       0.087\n",
      "Lag4          -0.0094      0.050     -0.187      0.851      -0.107       0.089\n",
      "Lag5          -0.0103      0.050     -0.208      0.835      -0.107       0.087\n",
      "Volume        -0.1354      0.158     -0.855      0.392      -0.446       0.175\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49291587 0.51853212 0.51886117 ... 0.4607317  0.47388171 0.48208344]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict()\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data set is splitted into two - before 2004 and after 2004\n",
      "Before 2004 is used as training set and after 2004 is test.\n",
      "\n",
      "Score of test data\n",
      "0.5595238095238095\n",
      "\n",
      " Predicted  Down   Up  All\n",
      "True                     \n",
      "Down         35   76  111\n",
      "Up           35  106  141\n",
      "All          70  182  252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ida_s\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Splitting in train and test set\n",
    "df_train = df[df.Year < 2005]\n",
    "df_test = df[df.Year == 2005]\n",
    "df_X_train = df_train[:][['Lag1', 'Lag2']]\n",
    "df_X_test = df_test[:][['Lag1', 'Lag2']]\n",
    "df_y_train = df_train[:]['Direction']\n",
    "df_y_test = df_test[:]['Direction']\n",
    "\n",
    "# Fitting the model based on train set\n",
    "lr = linear_model.LogisticRegression()\n",
    "ex = lr.fit(df_X_train, df_y_train)\n",
    "\n",
    "# Print\n",
    "print('\\nData set is splitted into two - before 2004 and after 2004\\nBefore 2004 is used as training set and after 2004 is test.')\n",
    "print('\\nScore of test data')\n",
    "print(lr.score(df_X_test, df_y_test))\n",
    "\n",
    "# Confusion matrix\n",
    "print('\\n',pd.crosstab(df_y_test, lr.predict(df_X_test), rownames=['True'], colnames=['Predicted'], margins=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.3 Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the Smarket data set is being used for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/Smarket.csv',usecols=range(1,10), index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][['Lag1','Lag2']]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "X_test = df['2005':][['Lag1','Lag2']]\n",
    "y_test = df['2005':]['Direction']\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "pred = lda.fit(X_train, y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probabilities of Groups:\n",
      " [0.49198397 0.50801603]\n"
     ]
    }
   ],
   "source": [
    "# pi_hat1 and pi_hat2\n",
    "priors = lda.priors_\n",
    "print('Prior probabilities of Groups:\\n', priors)\n",
    "# in other words, 49.2% of the training observations correspond to days during which the market went down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group mean:\n",
      " [[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n"
     ]
    }
   ],
   "source": [
    "m = lda.means_\n",
    "print('Group mean:\\n',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD coefficients:\n",
      " [[-0.64201904]\n",
      " [-0.51352928]]\n"
     ]
    }
   ],
   "source": [
    "# These do not seem to correspond to the values from the R output in the book?\n",
    "coef = lda.scalings_\n",
    "print('LD coefficients:\\n',coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 35  35]\n",
      " [ 76 106]]\n"
     ]
    }
   ],
   "source": [
    "# LDA prediction \n",
    "cmatrix = confusion_matrix(y_test, pred).T\n",
    "print('Confusion matrix:\\n',cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.500     0.315     0.387       111\n",
      "          Up      0.582     0.752     0.656       141\n",
      "\n",
      "   micro avg      0.560     0.560     0.560       252\n",
      "   macro avg      0.541     0.534     0.522       252\n",
      "weighted avg      0.546     0.560     0.538       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([ 70, 182], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50% threshold: allows us to recreate the predictions\n",
    "pred_p = lda.predict_proba(X_test)\n",
    "\n",
    "np.unique(pred_p[:,1]>0.5, return_counts=True)\n",
    "\n",
    "#Notice that the posterior probability output by the model corresponds to the probability that the market will decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False]), array([252], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90% threshold\n",
    "np.unique(pred_p[:,1]>0.9, return_counts=True)\n",
    "\n",
    "# No days in 2005 meet that threshold! In fact, the greatest posterior probability of decrease in all of 2005 was 52.02%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.4 Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "# QDA: The output contains the group means. But it does not contain the coefficients of the linear discriminants, because the QDA classifier involves a quadratic, rather than a linear, function of the predictors\n",
    "# Predict works as usually\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probabilities of Groups:\n",
      " [0.49198397 0.50801603]\n"
     ]
    }
   ],
   "source": [
    "p = qda.priors_\n",
    "print('Prior probabilities of Groups:\\n', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group means:\n",
      " [[ 0.04279022  0.03389409]\n",
      " [-0.03954635 -0.03132544]]\n"
     ]
    }
   ],
   "source": [
    "m = qda.means_\n",
    "print('Group means:\\n',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 30  20]\n",
      " [ 81 121]]\n"
     ]
    }
   ],
   "source": [
    "# This table gives the prediction for 2005 in the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred).T\n",
    "print('Confusion matrix:\\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.600     0.270     0.373       111\n",
      "          Up      0.599     0.858     0.706       141\n",
      "\n",
      "   micro avg      0.599     0.599     0.599       252\n",
      "   macro avg      0.600     0.564     0.539       252\n",
      "weighted avg      0.599     0.599     0.559       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, digits=3))\n",
    "# Se nederste: dette er den v√¶gtede gennemsnit: mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6.5 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[43 58]\n",
      " [68 83]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.426     0.387     0.406       111\n",
      "          Up      0.550     0.589     0.568       141\n",
      "\n",
      "   micro avg      0.500     0.500     0.500       252\n",
      "   macro avg      0.488     0.488     0.487       252\n",
      "weighted avg      0.495     0.500     0.497       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K = 1\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print('Confusion matrix:\\n',confusion_matrix(y_test, pred).T)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, pred, digits=3))\n",
    "# K = 1 are not very good, since only 50% of the observations are correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[48 55]\n",
      " [63 86]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.466     0.432     0.449       111\n",
      "          Up      0.577     0.610     0.593       141\n",
      "\n",
      "   micro avg      0.532     0.532     0.532       252\n",
      "   macro avg      0.522     0.521     0.521       252\n",
      "weighted avg      0.528     0.532     0.529       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K = 3\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print('Confusion matrix:\\n',confusion_matrix(y_test, pred).T)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results have improved slightly. But increasing K further turns out to provide no further improvements. \n",
    "It appears that for this data, QDA provides the best results of the methods that we have examined so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
